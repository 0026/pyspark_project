# PySpark Project ğŸš€

A structured **ETL pipeline project built with PySpark**.  
This repository demonstrates how to design, implement, and test scalable data pipelines using Apache Spark in Python.

---

## ğŸ“‚ Project Structure
```
pyspark_project/ 
â”œâ”€â”€ src/project_pyspark/ # Main source code for ETL pipeline 
â”œâ”€â”€ tests/ # Unit and integration tests 
â”œâ”€â”€ requirements.txt # Python dependencies 
â”œâ”€â”€ pyproject.toml # Project configuration 
â”œâ”€â”€ uv.lock # Lock file for uv package manager 
â”œâ”€â”€ README.md # Project documentation
â”œâ”€â”€ .gitignore # Git ignore rules 
â””â”€â”€ .python-version # Python version specification 
```
---


## âš™ï¸ Requirements

- **Python 3.10+** (see `.python-version`)
- **Apache Spark** (PySpark)
- Dependencies listed in `requirements.txt`

Install dependencies:

```bash
uv pip install -r requirements.txt
```

## â–¶ï¸ Usage
Run the main ETL pipeline:
```bash
uv run src/project_pyspark/main.py
```

## ğŸ§ª Testing
Run all tests with:
```bash
uv run pytest tests
```

## ğŸ“ Features
- Modular ETL pipeline with PySpark
- Logging integrated into main and ETL files
- Configurable parameters for flexible execution
- Unit tests for validation and reliability